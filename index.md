---
layout: frontpage
title: Bongjun Kim
description: Bongjun Kim is a Ph.D. candidate at Northwestern University. 
keywords: Machine learning, Audio, Human-Computer Interaction
---

<!-- ![profile_photo]({{ BASE_PATH }}/pages/files/bongjun_profile.jpg) -->


## Bongjun Kim  <a href="/images/me2.jpeg" target="_blank"><img src="../pages/files/bongjun_profile.jpg" width="35%" height="35%" align="right"></a>
Ph.D. Candidate, Computer Science <br>
Northwestern University <br>

<em>CV: </em><a href="{{ BASE_PATH }}/pages/files/BK_CV.pdf" target="_blank">PDF</a>  <small>(August, 2019)</small> <br>
<!-- <em>Email: </em><a href="mailto:bongjun@u.northwestern.edu">bongjun@u.northwestern.edu</a><br> -->
<em>Email:</em> bongjun [at] u.northwestern.edu<br>
**[Scholar](https://scholar.google.com/citations?hl=en&user=s5RiD14AAAAJ&view_op=list_works&sortby=pubdate) | [ResearchGate](https://www.researchgate.net/profile/Bongjun_Kim3) | [Github](https://github.com/bongjun) | [Linkedin](https://www.linkedin.com/in/bongjun-kim-3594334b/) | [twitter](https://twitter.com/iambongjun)**
<br>
<br>
<hr>
<!-- ### About Me -->
<!-- <p align="center">
  <img src="../pages/files/bongjun_profile.jpg" width="60%" height="60%">
  <br><br>
  <b><font size="5">Bongjun Kim | 김봉준</font></b><br>
  <br>
  <b><font size="3">(interactive) Machine Learning | Audio Signal Processing | HCI </font></b>
  <br><br>
</p>
 -->
<p align="center">
  <b><font size="3">(interactive) Machine Learning | Audio Signal Processing | HCI </font></b>
</p>

Bongjun Kim is a Ph.D. candidate in [the Department of Computer Science](https://www.mccormick.northwestern.edu/computer-science/) at [Northwestern University](https://www.northwestern.edu/) and working at [Interactive Audio Lab](http://music.cs.northwestern.edu/) with [Prof. Bryan Pardo](http://users.cs.northwestern.edu/~pardo/). His current research interests include **sound event detection**, **human-in-the-loop interfaces for audio annotation**, **interactive machine learning**, and **multimedia information retrieval**. He also enjoys working on a musical interface and interactive media art.

<hr>

### News
***8/29/2019***:&nbsp;&nbsp; My co-authored journal paper, *"Learning to Build Natural Audio Production Interfaces"* got published in [Arts](https://www.mdpi.com/2076-0752/8/3/110/htm)

***8/24/2019***:&nbsp;&nbsp; My co-authored paper, *"Classifying non-speech vocals: Deep vs Signal Processing Representations"* has been accepted from [DCASE 2019](http://dcase.community/workshop2019/)

***7/15/2019***:&nbsp;&nbsp; My paper, *"Sound Event Detection Using Point-labeled Data"* has been accepted from [WASPAA 2019](https://www.waspaa.com/)

***7/01/2019***:&nbsp; My DCASE submission (task 5) got **3rd** place out of 22 systems competing. (**2nd** in team rankings). Read more about the challenge and the results: [click](http://dcase.community/challenge2019/task-urban-sound-tagging-results).

***6/27/2019***:&nbsp;&nbsp; I am giving a talk about *"A Human-in-the-loop system for labeling sound events in audio recordings"* at [Midwest Music and Audio Day 2019 (MMAD)](https://sites.google.com/iu.edu/mmad2019) in Indiana University, Bloomington, USA.

***6/03/2019***:&nbsp;&nbsp; My paper, *"Self-supervised Attention Model for Weakly Labeled Audio Event Classification"* has been accepted from [EUSIPCO 2019](http://eusipco2019.org/)

***5/11/2019***:&nbsp;&nbsp; I am presenting my work, *"Improving Content-based Audio Retrieval by Vocal Imitation Feedback"* at [ICASSP 2019](https://2019.ieeeicassp.org/) in Brighten, UK.

***3/16/2019***:&nbsp;&nbsp; I am giving a talk about my work, *"A Human-in-the-loop System for Sound Event Detection and Annotation"* at [IUI 2019](https://iui.acm.org/2019/) in Los Angeles, USA.

***11/19/2018***:&nbsp; My sound classification model got **3rd** place (out of 23 systems competing) in [Making Sense of Sounds Data Challenge, 2018](https://cvssp.org/projects/making_sense_of_sounds/site/challenge/#results)

***11/19/2018***:&nbsp;&nbsp; I am presenting my work, *"Vocal Imitation Set: a dataset of vocally imitated sound events using the AudioSet ontology"* at [DCASE 2018](http://dcase.community/workshop2018/) in Surrey, UK.

<!-- <tr>
<td width="75"><b>June, 19'</b></td>
<td>My paper "Self-supervised Attention Model for Weakly Labeled Audio Event Classification" has been accepted from Eusipco2019.</td>
</tr>
 -->
<!-- <tr>
<td width="75"><b>Feb, 19'</b></td>
<td>TAing <a href="https://courses.soe.ucsc.edu/courses/cmps11/Spring19/01" target="_blank">CMPS 11</a> in Spring, 2019</td>
</tr>

<tr>
<td width="75"><b>Dec, 18'</b></td>
<td>Beginning to work with  <a href="http://www.yliuu.com/" target="_blank">Prof. Yang Liu</a> from Winter, 2019</td>
</tr>


<tr>
<td><b>Older</b></td>
<td><a href='news-archive' target="_blank">Archive</a></td>
</tr> -->

<!-- <hr>
### Selected Works

To be updated -->
<!-- [curriculum vitae ![CV as pdf]({{ BASE_PATH }}/pages/icons16/pdf-icon.png)]({{ BASE_PATH }}/assets/CV.pdf)<br/>
 -->


<!-- **Contact: bongjun[at]u.northwestern.edu** -->

---



<!-- <div class="container">
<h4><a name="contact"></a>contact</h4>
    <div class="row-fluid">
        <div class="span5">
            Bongjun Kim<br/>
            Email: bongjun at u.northwestern.edu[<br/>
        </div>
        <div class="span2">
        <a href="../assets/headshot.jpg">
            <img src="../assets/headshot.jpg"
                  title="Blue Ham" alt="Blue Ham"/></a>
        </div>
    </div>
</div> -->

<!-- <div class="navbar">
  <div class="navbar-inner">
      <ul class="nav">
          <li><a href="{{ BASE_PATH }}/assets/CV.pdf">cv</a></li>
          <li><a href="https://github.com/bongjun">GitHub</a></li>
          <li><a href="https://twitter.com/iambongjun">Twitter (@iambongjun)</a></li>
      </ul>
  </div>
</div> -->
